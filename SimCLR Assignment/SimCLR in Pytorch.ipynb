{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SimCLR in Pytorch.ipynb","provenance":[],"authorship_tag":"ABX9TyOoCJ/j4hctrfqQh7cXBVMM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l7mgSvZ6aqeB"},"source":["# CMPE 297 Homework - SimCLR Implementation in Pytorch\n","### Jimmy Liang\n","\n","Heavily borrowed from this blog and the accompanying code:\n","https://medium.com/analytics-vidhya/understanding-simclr-a-simple-framework-for-contrastive-learning-of-visual-representations-d544a9003f3c"]},{"cell_type":"code","metadata":{"id":"F0iZLJgsagjR","executionInfo":{"status":"ok","timestamp":1631840802923,"user_tz":420,"elapsed":6174,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["import numpy as np\n","import torch\n","from torchvision import transforms as T\n","from torchsummary import summary\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.models import resnet18\n","\n","import os\n","from PIL import Image\n","from collections import OrderedDict\n","\n","import random\n","\n","import matplotlib.pyplot as plt\n","from sklearn.manifold import TSNE\n","import seaborn as sns\n","tsne = TSNE()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_QLXHv5c2HZ","executionInfo":{"status":"ok","timestamp":1631840803084,"user_tz":420,"elapsed":165,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}},"outputId":"a2b6fc83-e70f-4a76-d654-4c3be441699b"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Sep 17 01:06:42 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   38C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"cvdCuDNBhOsb"},"source":["## Get Data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7xZgIZd7c-3v","executionInfo":{"status":"ok","timestamp":1631840809630,"user_tz":420,"elapsed":6547,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}},"outputId":"aff32178-60d1-49ed-ce18-16f74e7d24be"},"source":["!git clone https://github.com/thunderInfy/imagenet-5-categories"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'imagenet-5-categories'...\n","remote: Enumerating objects: 1532, done.\u001b[K\n","remote: Total 1532 (delta 0), reused 0 (delta 0), pack-reused 1532\u001b[K\n","Receiving objects: 100% (1532/1532), 88.56 MiB | 34.59 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n"]}]},{"cell_type":"code","metadata":{"id":"9_qolzTBdIJR","executionInfo":{"status":"ok","timestamp":1631840809630,"user_tz":420,"elapsed":14,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["device = torch.device('cuda')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"5JQTkxLEgTj_","executionInfo":{"status":"ok","timestamp":1631840809631,"user_tz":420,"elapsed":12,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["train_names = sorted(os.listdir('imagenet-5-categories/train'))\n","test_names = sorted(os.listdir('imagenet-5-categories/test'))\n","\n","random.seed(6)\n","\n","names_train_10_percent = random.sample(train_names, len(train_names) // 10)\n","names_train = random.sample(train_names, len(train_names))\n","names_test = random.sample(test_names, len(test_names))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RQH-Eytgx1P","executionInfo":{"status":"ok","timestamp":1631840809631,"user_tz":420,"elapsed":11,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["# defining a mapping between class names and numbers\n","mapping = {'car': 0, 'dog': 1, 'elephant': 2, 'cat': 3, 'airplane': 4}\n","inverse_mapping = ['car', 'dog', 'elephant', 'cat', 'airplane']\n","\n","# getting labels based on filenames, note that the filenames themselves contain classnames\n","# also note that these labels won't be used to actually train the base model\n","# these are just for visualization purposes\n","labels_train = [mapping[x.split('_')[0]] for x in names_train]\n","labels_test = [mapping[x.split('_')[0]] for x in names_test]\n","\n","# these 10 percent labels will be used for training the linear classifer\n","labels_train_10_percent = [mapping[x.split('_')[0]] for x in names_train_10_percent]"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q4YC4zmDhUxA","executionInfo":{"status":"ok","timestamp":1631840809631,"user_tz":420,"elapsed":11,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jZYyCSxShVo4"},"source":["## Helper Classes"]},{"cell_type":"code","metadata":{"id":"j3ot8ee1hW7v","executionInfo":{"status":"ok","timestamp":1631840809631,"user_tz":420,"elapsed":11,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["def get_color_distortion(s=1.0):\n","    color_jitter = T.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n","    rnd_color_jitter = T.RandomApply([color_jitter], p=0.8)\n","    \n","    # p is the probability of grayscale, here 0.2\n","    rnd_gray = T.RandomGrayscale(p=0.2)\n","    color_distort = T.Compose([rnd_color_jitter, rnd_gray])\n","    \n","    return color_distort"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"evSPaBPHhaQQ","executionInfo":{"status":"ok","timestamp":1631840809827,"user_tz":420,"elapsed":206,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["class MyDataset(Dataset):\n","    def __init__(self, root_dir, filenames, labels, mutation=False):\n","        self.root_dir = root_dir\n","        self.file_names = filenames\n","        self.labels = labels\n","        self.mutation = mutation\n","\n","    def __len__(self):\n","        return len(self.file_names)\n","\n","    def tensorify(self, img):\n","        res = T.ToTensor()(img)\n","        res = T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(res)\n","        return res\n","\n","    def mutate_image(self, img):\n","        res = T.RandomResizedCrop(224)(img)\n","        res = get_color_distortion(1)(res)\n","        return res\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir, self.file_names[idx])\n","        image = Image.open(img_name)\n","        label = self.labels[idx]\n","        image = T.Resize((250, 250))(image)\n","\n","        if self.mutation:\n","            image1 = self.mutate_image(image)\n","            image1 = self.tensorify(image1)\n","            image2 = self.mutate_image(image)\n","            image2 = self.tensorify(image2)\n","            sample = {'image1': image1, 'image2': image2, 'label': label}\n","        else:\n","            image = T.Resize((224, 224))(image)\n","            image = self.tensorify(image)\n","            sample = {'image': image, 'label': label}\n","\n","        return sample"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nk1FjW2GhyHQ","executionInfo":{"status":"ok","timestamp":1631840809827,"user_tz":420,"elapsed":7,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-DoArB_JiYIv"},"source":["## Creating Datasets"]},{"cell_type":"code","metadata":{"id":"PanWZ_G3ibJX","executionInfo":{"status":"ok","timestamp":1631840809828,"user_tz":420,"elapsed":7,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["# Datasets\n","\n","training_dataset_mutated = MyDataset('imagenet-5-categories/train', names_train, labels_train, mutation=True)\n","training_dataset = MyDataset('imagenet-5-categories/train', names_train_10_percent, labels_train_10_percent, mutation=False)\n","testing_dataset = MyDataset('imagenet-5-categories/test', names_test, labels_test, mutation=False)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"cLhDmJgDigqo","executionInfo":{"status":"ok","timestamp":1631840809829,"user_tz":420,"elapsed":7,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["# Dataloaders\n","\n","dataloader_training_dataset_mutated = DataLoader(training_dataset_mutated, batch_size=50, shuffle=True, num_workers=2)\n","dataloader_training_dataset = DataLoader(training_dataset, batch_size=25, shuffle=True, num_workers=2)\n","dataloader_testing_dataset = DataLoader(testing_dataset, batch_size=50, shuffle=True, num_workers=2)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"JeSxWTaqi6KI","executionInfo":{"status":"ok","timestamp":1631840809829,"user_tz":420,"elapsed":5,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BccigRSZjS6b"},"source":["## Define Architecture"]},{"cell_type":"code","metadata":{"id":"XbqiADq4jUcA","executionInfo":{"status":"ok","timestamp":1631840810235,"user_tz":420,"elapsed":411,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["# defining our deep learning architecture\n","resnet = resnet18(pretrained=False)\n","\n","classifier = nn.Sequential(OrderedDict([\n","    ('fc1', nn.Linear(resnet.fc.in_features, 100)),\n","    ('added_relu1', nn.ReLU(inplace=True)),\n","    ('fc2', nn.Linear(100, 50)),\n","    ('added_relu2', nn.ReLU(inplace=True)),\n","    ('fc3', nn.Linear(50, 25))\n","]))\n","\n","resnet.fc = classifier"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b4GItoJmjZIh","executionInfo":{"status":"ok","timestamp":1631840819277,"user_tz":420,"elapsed":9043,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}},"outputId":"b516342b-03f8-4c84-ed6e-deed575276ad"},"source":["resnet.to(device)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Sequential(\n","    (fc1): Linear(in_features=512, out_features=100, bias=True)\n","    (added_relu1): ReLU(inplace=True)\n","    (fc2): Linear(in_features=100, out_features=50, bias=True)\n","    (added_relu2): ReLU(inplace=True)\n","    (fc3): Linear(in_features=50, out_features=25, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"YhZDKyAqjiGI","executionInfo":{"status":"ok","timestamp":1631840819277,"user_tz":420,"elapsed":10,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nyumOiVZjz-j"},"source":["### Loss Function"]},{"cell_type":"code","metadata":{"id":"qMeRM1buj1eZ","executionInfo":{"status":"ok","timestamp":1631840819278,"user_tz":420,"elapsed":10,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["tau = 0.05\n","\n","def loss_function(a, b):\n","    a_norm = torch.norm(a, dim=1).reshape(-1, 1)\n","    a_cap = torch.div(a, a_norm)\n","    b_norm = torch.norm(b, dim=1).reshape(-1, 1)\n","    b_cap = torch.div(b, b_norm)\n","    a_cap_b_cap = torch.cat([a_cap, b_cap], dim=0)\n","    a_cap_b_cap_transpose = torch.t(a_cap_b_cap)\n","    b_cap_a_cap = torch.cat([b_cap, a_cap], dim=0)\n","    sim = torch.mm(a_cap_b_cap, a_cap_b_cap_transpose)\n","    sim_by_tau = torch.div(sim, tau)\n","    exp_sim_by_tau = torch.exp(sim_by_tau)\n","    sum_of_rows = torch.sum(exp_sim_by_tau, dim=1)\n","    exp_sim_by_tau_diag = torch.diag(exp_sim_by_tau)\n","    numerators = torch.exp(torch.div(torch.nn.CosineSimilarity()(a_cap_b_cap, b_cap_a_cap), tau))\n","    denominators = sum_of_rows - exp_sim_by_tau_diag\n","    num_by_den = torch.div(numerators, denominators)\n","    neglog_num_by_den = -torch.log(num_by_den)\n","    return torch.mean(neglog_num_by_den)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cni1Kfn1j2Hx","executionInfo":{"status":"ok","timestamp":1631840819416,"user_tz":420,"elapsed":148,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2_T9FiNAkBVA"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"Oz0N0ch-kCNw","executionInfo":{"status":"ok","timestamp":1631840819416,"user_tz":420,"elapsed":4,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":["# Defining data structures for storing training info\n","\n","losses_train = []\n","num_epochs = 10\n","\n","# using SGD optimizer\n","optimizer = optim.SGD(resnet.parameters(), lr=0.001, momentum=0.9)\n","\n","if not os.path.exists('results'):\n","    os.makedirs('results')\n","\n","# load pretrained model, optimizer and training losses file if model.pth file is available\n","if(os.path.isfile(\"results/model.pth\")):\n","    resnet.load_state_dict(torch.load(\"results/model.pth\"))\n","    optimizer.load_state_dict(torch.load(\"results/optimizer.pth\"))\n","\n","    for param_group in optimizer.param_groups:\n","        param_group['weight_decay'] = 1e-6\n","        param_group['lr'] = 0.000003\n","\n","    temp = np.load(\"results/lossesfile.npz\")\n","    losses_train = list(temp['arr_0'])"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyXKqcnxkE1R","executionInfo":{"status":"ok","timestamp":1631841065711,"user_tz":420,"elapsed":246298,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}},"outputId":"5975a65d-9633-4899-bc30-0b2620caec04"},"source":["# Boolean variable on whether to perform training or not \n","# Note that this training is unsupervised, it uses the NT-Xent Loss function\n","\n","TRAINING = True\n","\n","def get_mean_of_list(L):\n","    return sum(L) / len(L)\n","\n","if TRAINING:\n","    # get resnet in train mode\n","    resnet.train()\n","\n","    # run a for loop for num_epochs\n","    for epoch in range(num_epochs):\n","\n","        # a list to store losses for each epoch\n","        epoch_losses_train = []\n","\n","        # run a for loop for each batch\n","        for (_, sample_batched) in enumerate(dataloader_training_dataset_mutated):\n","            \n","            # zero out grads\n","            optimizer.zero_grad()\n","\n","            # retrieve x1 and x2 the two image batches\n","            x1 = sample_batched['image1']\n","            x2 = sample_batched['image2']\n","\n","            # move them to the device\n","            x1 = x1.to(device)\n","            x2 = x2.to(device)\n","\n","            # get their outputs\n","            y1 = resnet(x1)\n","            y2 = resnet(x2)\n","\n","            # get loss value\n","            loss = loss_function(y1, y2)\n","            \n","            # put that loss value in the epoch losses list\n","            epoch_losses_train.append(loss.cpu().data.item())\n","\n","            # perform backprop on loss value to get gradient values\n","            loss.backward()\n","\n","            # run the optimizer\n","            optimizer.step()\n","\n","        # append mean of epoch losses to losses_train, essentially this will reflect mean batch loss\n","        losses_train.append(get_mean_of_list(epoch_losses_train))\n","\n","        # Plot the training losses Graph and save it\n","        fig = plt.figure(figsize=(10, 10))\n","        sns.set_style('darkgrid')\n","        plt.plot(losses_train)\n","        plt.legend(['Training Losses'])\n","        plt.savefig('losses.png')\n","        plt.close()\n","\n","        # Store model and optimizer files\n","        torch.save(resnet.state_dict(), 'results/model.pth')\n","        torch.save(optimizer.state_dict(), 'results/optimizer.pth')\n","        np.savez(\"results/lossesfile\", np.array(losses_train))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"]}]},{"cell_type":"code","metadata":{"id":"UL1LCRO7kIfB","executionInfo":{"status":"ok","timestamp":1631841065712,"user_tz":420,"elapsed":10,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}}},"source":[""],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_9IBrBjkVVP","executionInfo":{"status":"ok","timestamp":1631841668075,"user_tz":420,"elapsed":25772,"user":{"displayName":"Jimmy Liang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18327941135693616169"}},"outputId":"89ebea30-cdf8-4e0d-ff4d-9666a68d5fb0"},"source":["# a function used to plot t-SNE visualizations\n","def plot_vecs_n_labels(v,labels,fname):\n","    fig = plt.figure(figsize = (10, 10))\n","    plt.axis('off')\n","    sns.set_style(\"darkgrid\")\n","    sns.scatterplot(v[:,0], v[:,1], hue=labels, legend='full', palette=sns.color_palette(\"bright\", labels.unique().shape[0]))\n","    plt.legend(['car', 'dog', 'elephant','cat','airplane'])\n","    plt.savefig(fname)\n","    plt.close()\n","\n","# Boolean variable to control whether to perform t-SNE visualization or not\n","TSNEVIS = True\n","\n","if TSNEVIS:\n","    # run resnet in eval mode\n","    resnet.eval()\n","\n","    # get TSNE visualizations of 10% training dataset\n","    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_train_last_layer.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None\n","\n","    # get TSNE visualizations of testing dataset\n","    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_test_last_layer.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None\n","\n","# Removing the last layer and the relu layer, we remove layers incrementally and look t-SNE visualizations\n","resnet.fc = nn.Sequential(*list(resnet.fc.children())[:-2])\n","\n","if TSNEVIS:\n","    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_train_second_last_layer.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None\n","\n","    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_test_second_last_layer.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None\n","\n","# removing one more layer, our entire projection head will be removed after this\n","resnet.fc = nn.Sequential(*list(resnet.fc.children())[:-1])\n","\n","if TSNEVIS:\n","    for (_, sample_batched) in enumerate(dataloader_training_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_hidden_train.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None\n","\n","    for (_, sample_batched) in enumerate(dataloader_testing_dataset):\n","        x = sample_batched['image']\n","        x = x.to(device)\n","        y = resnet(x)\n","        y_tsne = tsne.fit_transform(y.cpu().data)\n","        labels = sample_batched['label']\n","        plot_vecs_n_labels(y_tsne,labels,'tsne_hidden_test.png')\n","        x = None\n","        y = None\n","        y_tsne = None\n","        sample_batched = None"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n","/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]}]}]}