{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language Model - Multiple Choice.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88facf2a64914006a50a7c7fadcbb98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d0e1a2a66fe548ce9c5b54c90ff54774",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9a283c0fb6f84f76ac9b21a936b9e0b4",
              "IPY_MODEL_841da38707d64ec185a45aae32d28f42",
              "IPY_MODEL_1728d77827e5497588b6c7b8c3588d34"
            ]
          }
        },
        "d0e1a2a66fe548ce9c5b54c90ff54774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a283c0fb6f84f76ac9b21a936b9e0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_75a06856583a47569c9f6668f17a3453",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ffb61415a1843e09bb643ec07869049"
          }
        },
        "841da38707d64ec185a45aae32d28f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c00082d2ec8343e0a8220a5dde4ac951",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0228c9b5a1374146be29675dbac51293"
          }
        },
        "1728d77827e5497588b6c7b8c3588d34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_342707ee4e0c46dabe51cdf30e013380",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7.97k/? [00:00&lt;00:00, 15.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_50d06f04ffe541608995a1786d550439"
          }
        },
        "75a06856583a47569c9f6668f17a3453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ffb61415a1843e09bb643ec07869049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c00082d2ec8343e0a8220a5dde4ac951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0228c9b5a1374146be29675dbac51293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "342707ee4e0c46dabe51cdf30e013380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "50d06f04ffe541608995a1786d550439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8WOn0DAOw3b"
      },
      "source": [
        "#Assignment 3 - Fine Tuning a Language Model\n",
        "##Multiple Choice\n",
        "Following Huggingface example - https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/multiple_choice.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqFvlRvsP_t1",
        "outputId": "7f36b1a6-9bf4-47dd-9516-66d20460baec"
      },
      "source": [
        "! pip install datasets transformers seqeval rouge-score nltk gradio"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.12.1-py3-none-any.whl (270 kB)\n",
            "\u001b[K     |████████████████████████████████| 270 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 38.1 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Collecting gradio\n",
            "  Downloading gradio-2.3.6-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 28.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 44.8 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 27.6 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.10.0-py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 37.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n",
            "Collecting huggingface-hub<0.1.0,>=0.0.14\n",
            "  Downloading huggingface_hub-0.0.19-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0,>=0.0.14->datasets) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 44.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge-score) (1.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge-score) (0.12.0)\n",
            "Collecting paramiko\n",
            "  Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting Flask-Cors>=3.0.8\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.11.0-cp35-abi3-manylinux2010_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 45.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Flask>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from gradio) (1.1.4)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting markdown2\n",
            "  Downloading markdown2-2.4.1-py2.py3-none-any.whl (34 kB)\n",
            "Collecting Flask-Login\n",
            "  Downloading Flask_Login-0.5.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting flask-cachebuster\n",
            "  Downloading Flask-CacheBuster-1.0.0.tar.gz (3.1 kB)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (7.1.2)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.1->gradio) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.1.1->gradio) (2.0.1)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 47.5 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Collecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)\n",
            "\u001b[K     |████████████████████████████████| 961 kB 46.2 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.5\n",
            "  Downloading cryptography-35.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 48.0 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.14.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.20)\n",
            "Building wheels for collected packages: seqeval, ffmpy, flask-cachebuster\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=52ce59bbf43eb3fbf6f56b9a2726bf3290b018e875644242175db8369058aedb\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4710 sha256=34c845d51f21a25bb8608669c646646db920a2cea00993e7fe1933a984c1c381\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for flask-cachebuster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-cachebuster: filename=Flask_CacheBuster-1.0.0-py3-none-any.whl size=3371 sha256=6aa31ad725eb00c023ce801ce8af176322c3d3279a501e0f3092b976d12171c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/c0/c4/44687421dab41455be93112bd1b0dee1f3c5a9aa27bee63708\n",
            "Successfully built seqeval ffmpy flask-cachebuster\n",
            "Installing collected packages: multidict, yarl, async-timeout, pyyaml, pynacl, monotonic, fsspec, cryptography, bcrypt, backoff, aiohttp, xxhash, tokenizers, sacremoses, pycryptodome, paramiko, markdown2, huggingface-hub, Flask-Login, Flask-Cors, flask-cachebuster, ffmpy, analytics-python, transformers, seqeval, rouge-score, gradio, datasets\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed Flask-Cors-3.0.10 Flask-Login-0.5.0 aiohttp-3.7.4.post0 analytics-python-1.4.0 async-timeout-3.0.1 backoff-1.10.0 bcrypt-3.2.0 cryptography-35.0.0 datasets-1.12.1 ffmpy-0.3.0 flask-cachebuster-1.0.0 fsspec-2021.10.0 gradio-2.3.6 huggingface-hub-0.0.19 markdown2-2.4.1 monotonic-1.6 multidict-5.2.0 paramiko-2.8.0 pycryptodome-3.11.0 pynacl-1.4.0 pyyaml-5.4.1 rouge-score-0.0.4 sacremoses-0.0.46 seqeval-1.2.2 tokenizers-0.10.3 transformers-4.11.3 xxhash-2.0.2 yarl-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeWtRsijOtkV",
        "outputId": "82ac62bd-5864-4a91-8cce-4531cfc50a6d"
      },
      "source": [
        "# Do all the imports\n",
        "\n",
        "import numpy as np\n",
        "from datasets import load_dataset, load_metric\n",
        "from datasets import ClassLabel, Sequence\n",
        "import random\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.11.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1BeOwQRP4ol"
      },
      "source": [
        "model_checkpoint = \"bert-base-uncased\"\n",
        "batch_size = 16\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "88facf2a64914006a50a7c7fadcbb98b",
            "d0e1a2a66fe548ce9c5b54c90ff54774",
            "9a283c0fb6f84f76ac9b21a936b9e0b4",
            "841da38707d64ec185a45aae32d28f42",
            "1728d77827e5497588b6c7b8c3588d34",
            "75a06856583a47569c9f6668f17a3453",
            "4ffb61415a1843e09bb643ec07869049",
            "c00082d2ec8343e0a8220a5dde4ac951",
            "0228c9b5a1374146be29675dbac51293",
            "342707ee4e0c46dabe51cdf30e013380",
            "50d06f04ffe541608995a1786d550439"
          ]
        },
        "id": "iMVXG3NGQzEq",
        "outputId": "46df367b-566e-4210-f9ed-24a5011eae8a"
      },
      "source": [
        "# Load the training dataset\n",
        "\n",
        "datasets = load_dataset(\"swag\", \"regular\")\n",
        "datasets"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88facf2a64914006a50a7c7fadcbb98b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.35k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a1cea2c935044b96a27c7dfa834d72b9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset swag/regular (download: 41.92 MiB, generated: 44.96 MiB, post-processed: Unknown size, total: 86.88 MiB) to /root/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "21378fa9b46c4078b360d4e619f330de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3252304b77734f569bb64232575ffacc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/6.71M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a78a54bf91d46b18432e592dd6bfda1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a161dd3a1f048d1ae3ce94a5ff70c5d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b33b6bd33d114739998b0f9d4c18ebcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e466e3e497d9489fb8ca20823bc4088a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b1432d5f1924841b745a726102ff970",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9366ad85d60452bb51b1181b294b860",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset swag downloaded and prepared to /root/.cache/huggingface/datasets/swag/regular/0.0.0/9640de08cdba6a1469ed3834fcab4b8ad8e38caf5d1ba5e7436d8b1fd067ad4c. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fccb953a319418aae793c24f01e3320",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
              "        num_rows: 73546\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
              "        num_rows: 20006\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['video-id', 'fold-ind', 'startphrase', 'sent1', 'sent2', 'gold-source', 'ending0', 'ending1', 'ending2', 'ending3', 'label'],\n",
              "        num_rows: 20005\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo5xiSQjRAgh",
        "outputId": "eb00555e-0591-4c3e-c079-1eba619578c0"
      },
      "source": [
        "datasets['train'][100]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ending0': 'laughs as the insides place her hand around her thighs.',\n",
              " 'ending1': 'arrange the wrapping paper and straightens the gift paper.',\n",
              " 'ending2': 'paints in wrapping paper.',\n",
              " 'ending3': 'folds paper ribbon for me and then puts it in the cellophane.',\n",
              " 'fold-ind': '16950',\n",
              " 'gold-source': 'gen',\n",
              " 'label': 1,\n",
              " 'sent1': 'We see the girl puts gifts into a gift bag with tissue paper.',\n",
              " 'sent2': 'The girl',\n",
              " 'startphrase': 'We see the girl puts gifts into a gift bag with tissue paper. The girl',\n",
              " 'video-id': 'anetv_rS8T1dAdiCs'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcnxwR3iSaKX"
      },
      "source": [
        "def show_one(example):\n",
        "    print(f\"Context: {example['sent1']}\")\n",
        "    print(f\"  A - {example['sent2']} {example['ending0']}\")\n",
        "    print(f\"  B - {example['sent2']} {example['ending1']}\")\n",
        "    print(f\"  C - {example['sent2']} {example['ending2']}\")\n",
        "    print(f\"  D - {example['sent2']} {example['ending3']}\")\n",
        "    print(f\"\\nGround truth: option {['A', 'B', 'C', 'D'][example['label']]}\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gstk9KOeE6SG",
        "outputId": "9397020d-6c9b-4ad8-ef06-6fdab34b5955"
      },
      "source": [
        "show_one(datasets[\"train\"][100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context: We see the girl puts gifts into a gift bag with tissue paper.\n",
            "  A - The girl laughs as the insides place her hand around her thighs.\n",
            "  B - The girl arrange the wrapping paper and straightens the gift paper.\n",
            "  C - The girl paints in wrapping paper.\n",
            "  D - The girl folds paper ribbon for me and then puts it in the cellophane.\n",
            "\n",
            "Ground truth: option B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQM4kJfOSsEC"
      },
      "source": [
        "## Preprocess the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMEGNpsMStpR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "0ef034e5-6d81-46c3-82a2-6886d6fd1cae"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00278643c9df4beeb015064fc7bddab0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "966e41aed8474317afd1f01eb7a9547e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07a2ff8d981c4eadb39548c77527e2c0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1891a50863e64e7386ab8a9ec83e847e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytn2ch5icK34"
      },
      "source": [
        "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    # Repeat each first sentence four times to go with the four possibilities of second sentences.\n",
        "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
        "    # Grab all second sentences possible for each context.\n",
        "    question_headers = examples[\"sent2\"]\n",
        "    second_sentences = [[f\"{header} {examples[end][i]}\" for end in ending_names] for i, header in enumerate(question_headers)]\n",
        "    \n",
        "    # Flatten everything\n",
        "    first_sentences = sum(first_sentences, [])\n",
        "    second_sentences = sum(second_sentences, [])\n",
        "    \n",
        "    # Tokenize\n",
        "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
        "    # Un-flatten\n",
        "    return {k: [v[i:i+4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smw_yJhb7_Pd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        },
        "outputId": "a9c2410d-e85c-467f-bf09-fbe498bdd701"
      },
      "source": [
        "encoded_datasets = datasets.map(preprocess_function, batched=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e0a5a5437ae4ec99a825bf9014e5afc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/74 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8ca58b22a264218a59a99f6cd5e03b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/21 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6bcd9928ef2443aadd8db005c49b3d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/21 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYW-BMMB8OZu"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2141r58Oht"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-PPhC4ecPpF"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71YnoaqYcOT_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "a3ac982f-8f15-4ed1-e7c3-2838f163c4c3"
      },
      "source": [
        "from transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbfc07e7d9b94db19fbc549188869045",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultipleChoice: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMultipleChoice from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultipleChoice from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsyySSZAcUII",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf97460-f3fd-42f9-f2cb-a83c5e70207c"
      },
      "source": [
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-swag\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ect7PVxYcW34"
      },
      "source": [
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from typing import Optional, Union\n",
        "import torch\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0].keys() else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "        num_choices = len(features[0][\"input_ids\"])\n",
        "        flattened_features = [[{k: v[i] for k, v in feature.items()} for i in range(num_choices)] for feature in features]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "        \n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        \n",
        "        # Un-flatten\n",
        "        batch = {k: v.view(batch_size, num_choices, -1) for k, v in batch.items()}\n",
        "        # Add back labels\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n",
        "        return batch"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfwjHZMNceIL"
      },
      "source": [
        "accepted_keys = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "features = [{k: v for k, v in encoded_datasets[\"train\"][i].items() if k in accepted_keys} for i in range(10)]\n",
        "batch = DataCollatorForMultipleChoice(tokenizer)(features)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LUMk5gJcgWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffec2d8-1f33-4fee-a298-ac50e91bd16f"
      },
      "source": [
        "[tokenizer.decode(batch[\"input_ids\"][8][i].tolist()) for i in range(4)]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] someone walks over to the radio. [SEP] someone hands her another phone. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
              " '[CLS] someone walks over to the radio. [SEP] someone takes the drink, then holds it. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
              " '[CLS] someone walks over to the radio. [SEP] someone looks off then looks at someone. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
              " '[CLS] someone walks over to the radio. [SEP] someone stares blearily down at the floor. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiP0KScEGrbN"
      },
      "source": [
        "def compute_metrics(eval_predictions):\n",
        "    predictions, label_ids = eval_predictions\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    return {\"accuracy\": (preds == label_ids).astype(np.float32).mean().item()}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyaGwrUzGtki"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=encoded_datasets[\"train\"],\n",
        "    eval_dataset=encoded_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForMultipleChoice(tokenizer),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0WI5iM_uGuRp",
        "outputId": "e17d9f6b-575a-4879-dde7-8eea704487a5"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: ending2, ending3, sent1, ending0, gold-source, startphrase, sent2, video-id, ending1, fold-ind.\n",
            "***** Running training *****\n",
            "  Num examples = 73546\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4597\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4597' max='4597' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4597/4597 1:34:59, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.705200</td>\n",
              "      <td>0.533229</td>\n",
              "      <td>0.793412</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-500\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-500/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-1000\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-1000/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-1500\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-1500/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-2000\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-2000/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-2500\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-2500/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-3000\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-3000/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-3000/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-3500\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-3500/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-4000\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-4000/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-4000/special_tokens_map.json\n",
            "Saving model checkpoint to bert-base-uncased-finetuned-swag/checkpoint-4500\n",
            "Configuration saved in bert-base-uncased-finetuned-swag/checkpoint-4500/config.json\n",
            "Model weights saved in bert-base-uncased-finetuned-swag/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in bert-base-uncased-finetuned-swag/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in bert-base-uncased-finetuned-swag/checkpoint-4500/special_tokens_map.json\n",
            "The following columns in the evaluation set  don't have a corresponding argument in `BertForMultipleChoice.forward` and have been ignored: ending2, ending3, sent1, ending0, gold-source, startphrase, sent2, video-id, ending1, fold-ind.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 20006\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4597, training_loss=0.6448269010705224, metrics={'train_runtime': 5701.5775, 'train_samples_per_second': 12.899, 'train_steps_per_second': 0.806, 'total_flos': 8225398515002448.0, 'train_loss': 0.6448269010705224, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxu0YAbjQjuk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vsdQPHBYNHO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}